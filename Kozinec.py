import numpy as np
from math  import log 
#Обучающие выборки
X_1 = [
    [0.7295200749361322, 0.7286337326606256],
    [0.826505923560258, 0.9403158114766519],
    [0.6023139955320228, 0.4890999051968531],
    [0.7924301535257385, 0.9724603339895345],
    [0.3739062132424882, 0.3807945141554343],
    [0.5213825315815278, 0.7011647516840395],
    [0.5799489554848042, 0.860210492806848],
    [0.4472712889659769, 0.23208680582951224],
    [0.8266928088733442, 0.9708616047497776],
    [0.2096090384196102, 0.07948946448504302],
    [0.33832612728389067, 0.4113630733104253],
    [0.68383264433507, 0.9003136248995234],
    [0.3974079484193441, 0.44643242592599985],
    [0.26193673674112883, 0.20727182114712916]
  ]
X_2 = [
    [0.846590438950232, 0.12680486596335516],
    [0.11671041192819076, 0.8523469688748586],
    [0.8939436660435063, 0.20441969005621619],
    [0.196515524259539, 0.7563403480339516],
    [0.762462325724514, 0.17675381094088127],
    [0.8646206065391742, 0.4289513713302239],
    [0.7086382515784717, 0.1718070095596751],
    [0.07308462517167347, 0.7068687883532849],
    [0.7429722924973284, 0.19681071128913086],
    [0.685062552324161, 0.011556200983953824],
    [0.05599840395566957, 0.5147182562252324],
    [0.9645548277207796, 0.4500437929854587],
    [0.25076267013066156, 0.8845898320940508],
    [0.12851981469617013, 0.7983431014344502],
    [0.01817344753341743, 0.845385785214988]
  ]
X_3 = [[0.6721751810634596, 0.18449311250437642],
    [-0.042169919316812694, 0.49680717330122753],
    [0.036908766218045196, 0.23196814194239498],
    [-0.18516646555268645, -0.16324434635897248],
    [0.19909138385183697, -0.20702094026594725],
    [-0.2623894406811841, 0.4468810030788092],
    [0.619550362174564, 0.03980697858179339],
    [0.4418628679007078, -0.0039497588794656585],
    [0.2802286875966722, -0.3525718017732991],
    [0.07448927922989906, -0.4973644925498143],
    [0.6422888179711995, -0.0035410965993326157],
    [0.039664220315716536, 0.34884886593497205],
    [0.4825251758452453, 0.5597992922297098],
    [-0.12480141590985117, 0.3639607311580515],
    [0.45864564291438903, 0.5039088481769888],
    [0.4953345038557703, 0.29819697998837763],
    [0.2106700620743459, -0.2647756656167547],
    [-0.16518914904666915, 0.31212217489262595],
    [0.23046293495668924, -0.013246417684656153]
    ] 
# Вероятность того, что вектор належить розподілу
teta = 0.8

E = np.array([[1,0],[0,1]])# Дисперсия
A = np.linalg.inv(E) 
print ("E = \n",A)
m = np.array([0,0])# мат ожидание
print ("m = ",m)
k = 2*log(teta) + m.dot(A.dot(m)) # константа
print ("k = ",k)
#v_1 = np.array([1,0]) # собственный вектор
#искривля пространство, получаем кси от х и L от A,m,k
def ksi(x):
  """
  >>> ksi([1,0])
  array([1, 0, 0, 0, 1, 1, 0, 0, 1])
  """
  ksi = []
  for j in range (0,2*len(x)):
    for i in range(0,len(x)):
      #print(i+len(x)*j,len(x)*len(x))
      if i+len(x)*j < len(x)*len(x): ksi.append(x[i]*x[j])#, print (x[i]*x[j])
      else: ksi.append(x[j - len(x)]) #, ksi.append(x[j - len(x)])
  ksi.append(1) 
  #print ("ksi(x) = ", ksi)
  return np.array(ksi)

def L (A,m,k):
  """
  >>> L ([[1,0],[0,1]],[0,0],-0.4462871026284194)
  array([ 1.       ,  0.       ,  0.       ,  1.       ,  0.       ,
          0.       ,  0.       ,  0.       , -0.4462871])
  """
  L = []
  for j in range (0,2*len(m)):
    for i in range(0,len(m)):
      if i+len(m)*j < len(m)*len(m): L.append(A[i][j])
      else: L.append(-2*m[i]*A[i][j - len(m)])#, print (m[i],A[i][j - len(m)])
  L.append(k) 
  #print ("L = ", L)
  return np.array(L)
#Поиск нового гаммы 
#-----------------------------------------------------------------------------------------------
def Gamma_new (x,L):
  """
  >>> Gamma_new ([1,0],[ 1.       ,  0.       ,  0.       ,  1.       ,  0.       ,0.       ,  0.       ,  0.       , -0.4462871])
  array(0.62323299)
  """
  ksi_ = ksi(x)
  #print (ksi_)
  Gamma_new = max((np.dot(ksi_,L+ksi_))/(np.dot((L+ksi_),(L+ksi_))),0)
  #print ("Gamma_new =",Gamma_new)
  return np.array(Gamma_new)
#Поиск нового L
def L_new (Gamma,x,L):
  """
  >>> L_new (1,[1,0],[ 1.       ,  0.       ,  0.       ,  1.       ,  0.       ,0.       ,  0.       ,  0.       ,1])
  L_new = [1. 0. 0. 1. 0. 0. 0. 0. 1.]
  array([1., 0., 0., 1., 0., 0., 0., 0., 1.])
  """
  ksi_ = ksi(x)
  L_new = L*Gamma + (1 - Gamma)*ksi_
  print ("L_new =",L_new)
  return  np.array(L_new)

# Алгоритм козинца
def Kozinec(L,X): #Алгоритм козинца
  #d = len(X)
  """
  >>> Kozinec([ 1.       ,  0.       ,  0.       ,  1.       ,  0.       ,0.       ,  0.       ,  0.       ,1],[[1., 0.],[0., 1]])
  [1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1]
  """
  d = 0 # Специально берем 1 или 2 елемента из выборки, иначе на выходе одни единицы.
  for i in range (d):
    x = X[i]
    ksi_ = ksi(x) 
    
    if np.dot(L,ksi_) < 0: 
      Gamma = Gamma_new (x,L) 
      print ("Gamma =",Gamma)
      L = L_new (Gamma,x,L)
      print ("L * ksi_ = ",L.dot(ksi_), i )
      Kozinec(L,X) 
  return L
# Я осмелился предложить другую фунцию, кторая нагляднее будет показывать, какие вектора принадлежат распределению а какие нет.
def Search_Kozinec(X, L):
  """
  >>> Search_Kozinec([[1., 0.],[0., 1]], [ 1.       ,  0.       ,  0.       ,  1.       ,  0.       ,0.       ,  0.       ,  0.       ,1])
  [1, 1]

  """
  Mark = []
  for i in range (len(X)):
    x = X[i]
    ksi_ = ksi(x) 
    #print ("L * ksi_ = ",L.dot(ksi_) )
    if np.dot(L,ksi_) < 0: Mark.append(0)
    else: Mark.append(1)
  return Mark

L1 = L (A,m,k)
L2 = L (A,m,k)

L_1 = Kozinec(L1, X_1)
L_2 = Kozinec(L2, X_2)

Mark_1 = Search_Kozinec(X_1, L_1)
Mark_2 = Search_Kozinec(X_2, L_2)
Mark_1_3 = Search_Kozinec(X_3, L_1)
Mark_2_3 = Search_Kozinec(X_3, L_2)


print ("\nL_1_final = ", L_1)
print ("\nMark_1 = ", Mark_1)
print ("\nL_2_final = ", L_2)
print ("\nMark_2 = ", Mark_2)

print ("\nMark_1_3 = ", Mark_1_3)
print ("\nMark_2_3 = ", Mark_2_3)

if __name__ == "__main__":
  import doctest
  doctest.testmod()

